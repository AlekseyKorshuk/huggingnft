{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1080918d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/AlekseyKorshuk/huggingnft\n",
    "%cd huggingnft\n",
    "!pip install .\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409b4d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_api_key = \"93445d44a79e52c3bb20f5b2e8bd7d5d9d838dc0\" #@param {type:\"string\"}\n",
    "assert wandb_api_key != \"\", \"It is important to track training progress with WANDB\"\n",
    "from huggingface_hub.hf_api import HfApi\n",
    "import os\n",
    "os.environ['WANDB_API_KEY'] = wandb_api_key\n",
    "hfapi = HfApi()\n",
    "token = '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'#\"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\"\n",
    "hfapi.set_access_token(token)\n",
    "!mkdir /root/.huggingface -p\n",
    "\n",
    "with open(\"/root/.huggingface/token\", \"w+\") as text_file:\n",
    "    text_file.write(token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96a2406",
   "metadata": {},
   "outputs": [],
   "source": [
    "!accelerate config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020aca4f",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4634e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_NFT_collections = sorted( [datainfo.id for datainfo in hfapi.list_datasets(author=\"huggingnft\") \\\n",
    "                           if datainfo.id.split('/')[-1] ] )\n",
    "\n",
    "collectionA = ''\n",
    "collectionB = ''\n",
    "assert collectionA in hf_NFT_collections and collectionB in hf_NFT_collections, f'Error, collectionA and collectionB must be one of {hf_NFT_collections}'\n",
    "\n",
    "hyperparams_cyclegan = { \n",
    "                'lr':[0.0002], \n",
    "                'num_epochs':[200], \n",
    "                'decay_epoch':[80] ,\n",
    "                'n_residual_blocks':[9], \n",
    "                'lambda_cyc':[10.0], \n",
    "                'lambda_id':[5.0], \n",
    "                'beta1':[0.5], 'beta2':[0.999], \n",
    "                'batch_size':[8], \n",
    "                'source_dataset_name':[f'huggingnft/{collectionA}'],\n",
    "                'target_dataset_name':[f'huggingnft/{collectionB}'],\n",
    "                'channels':[3], \n",
    "                'checkpoint_interval':[5], \n",
    "                #'cpu':[False], \n",
    "                'epoch':[0], \n",
    "                #'fp16':[False], \n",
    "                'image_size':[256],\n",
    "                'mixed_precision':['no'], \n",
    "                'num_workers':[8], \n",
    "                'organization_name':['huggingnft'], \n",
    "                'wandb':[True],\n",
    "                'push_to_hub':[True], \n",
    "                'model_name':['cyclegan'],\n",
    "                'sample_interval':[10] }\n",
    "\n",
    "call_params = ['accelerate', 'launch',\n",
    "                       '--config_file','~/.cache/huggingface/accelerate/default_config.yaml',\n",
    "                       'train.py']\n",
    "for idx, grid in enumerate(ParameterGrid(hyperparams_cyclegan)):\n",
    "        grid['output_dir'] = 'experiments'\n",
    "\n",
    "        for k,v in grid.items():\n",
    "\n",
    "            if k in  ['cpu', 'wandb','fp16','push_to_hub']:\n",
    "                if v is True:\n",
    "                    call_params.append(f'--{k}' )\n",
    "            else:\n",
    "                call_params.append(f'--{k}' )\n",
    "                call_params.append(f'{v}' )\n",
    "\n",
    "        print(' '.join(call_params))\n",
    "        call(call_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556cd4b9",
   "metadata": {},
   "source": [
    "# Train all possible translation models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596892bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "from subprocess import call\n",
    "import os\n",
    "import json\n",
    "from huggingface_hub.hf_api import HfApi\n",
    "import copy\n",
    "\n",
    "\n",
    "hfapi = HfApi()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac13bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/100] [Batch 464/541] [D loss: 0.161642] [G loss: 2.767825, adv: 0.477216, cycle: 0.164036, identity: 0.130049] ETA: 15:31:53.088550014346"
     ]
    }
   ],
   "source": [
    "hf_NFT_collections = sorted( [datainfo.id for datainfo in hfapi.list_datasets(author=\"huggingnft\") \\\n",
    "                           if datainfo.id.split('/')[-1] ] )\n",
    "\n",
    "\n",
    "cnt = 1\n",
    "total = len(hf_NFT_collections)* (len(hf_NFT_collections) -1)//2\n",
    "for idx1, hf_datapath1 in enumerate(hf_NFT_collections):\n",
    "    for idx2 in range(idx1+1, len(hf_NFT_collections) )  :\n",
    "        hf_datapath2 = hf_datasets_info[idx2] \n",
    "        collectionA = hf_datapath1.split('/')[-1]\n",
    "        collectionB = hf_datapath2.split('/')[-1]\n",
    "        \n",
    "        model_name = f'{collectionA}__2__{collectionB}'\n",
    "        \n",
    "        if model_name not in created_models:\n",
    "            print(f'[{cnt }/{total}] - Creating {model_name}')\n",
    "        else:\n",
    "            print(f'[{cnt }/{total}] - Already created {model_name}')\n",
    "  \n",
    "        hyperparams_cyclegan = { \n",
    "                'lr':[0.0002], \n",
    "                'num_epochs':[200], \n",
    "                'decay_epoch':[80] ,\n",
    "                'n_residual_blocks':[9], \n",
    "                'lambda_cyc':[10.0], \n",
    "                'lambda_id':[5.0], \n",
    "                'beta1':[0.5], 'beta2':[0.999], \n",
    "                'batch_size':[8], \n",
    "                'source_dataset_name':[f'huggingnft/{collectionA}'],\n",
    "                'target_dataset_name':[f'huggingnft/{collectionB}'],\n",
    "                'channels':[3], \n",
    "                'checkpoint_interval':[5], \n",
    "                #'cpu':[False], \n",
    "                'epoch':[0], \n",
    "                #'fp16':[False], \n",
    "                'image_size':[256],\n",
    "                'mixed_precision':['no'], \n",
    "                'num_workers':[8], \n",
    "                'organization_name':['huggingnft'], \n",
    "                'wandb':[True],\n",
    "                'push_to_hub':[True], \n",
    "                'model_name':['cyclegan'],\n",
    "                'sample_interval':[10] }\n",
    "\n",
    "\n",
    "        call_params = ['accelerate', 'launch',\n",
    "                               '--config_file','~/.cache/huggingface/accelerate/default_config.yaml',\n",
    "                               'train.py']\n",
    "        for idx, grid in enumerate(ParameterGrid(hyperparams_cyclegan)):\n",
    "                grid['output_dir'] = 'experiments'\n",
    "\n",
    "                for k,v in grid.items():\n",
    "\n",
    "                    if k in  ['cpu', 'wandb','fp16','push_to_hub']:\n",
    "                        if v is True:\n",
    "                            call_params.append(f'--{k}' )\n",
    "                    else:\n",
    "                        call_params.append(f'--{k}' )\n",
    "                        call_params.append(f'{v}' )\n",
    "\n",
    "                print(' '.join(call_params))\n",
    "                call(call_params)\n",
    "   \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        cnt += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hugenv",
   "language": "python",
   "name": "hugenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
